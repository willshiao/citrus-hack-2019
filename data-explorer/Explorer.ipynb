{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import spacy\n",
    "import multiprocessing \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFile = \"../data/cleaned.csv\"\n",
    "data1 = pd.read_csv(dataFile)\n",
    "data2 = pd.read_csv('../data/hate_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2.drop(data2[data2['Class'] == 'neither'].index)\n",
    "data2['Class'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4be204daba5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data[data['Class'] == 1].tail(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_whitelist = set(['ADJ', 'ADV', 'PROPN', 'VERB', 'NOUN', 'INTJ', 'PRON', 'X', 'NUM'])\n",
    "whitelist = set(string.ascii_lowercase + string.digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "megaSpam = pd.read_csv('../data/polluters.tsv', sep='\\t')\n",
    "megaNonSpam = pd.read_csv('../data/legit.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "megaSpam['Class'] = 1\n",
    "megaNonSpam['Class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/citrus2019/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FavCount</th>\n",
       "      <th>RtCount</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Text</th>\n",
       "      <th>TweetID</th>\n",
       "      <th>Verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Tactical_Things</td>\n",
       "      <td>RT @HouseOfTraitors: FARAGE  12  -  0 Mandelsc...</td>\n",
       "      <td>732588910078001152</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>kataisa</td>\n",
       "      <td>@TheBriefing2016 @HillaryClinton Can Hillary s...</td>\n",
       "      <td>732588910073778176</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5423.0</td>\n",
       "      <td>Josh_Ward_</td>\n",
       "      <td>RT @HQUESTED: Harvey price just said cunt on n...</td>\n",
       "      <td>732588910061232128</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>networkMCI</td>\n",
       "      <td>@xonighttimexo I will put them in a Safety dep...</td>\n",
       "      <td>732588910056902656</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nbharper</td>\n",
       "      <td>you should listen, but you probably won't bc y...</td>\n",
       "      <td>732588910069620736</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  FavCount  RtCount       ScreenName  \\\n",
       "0      0       0.0      8.0  Tactical_Things   \n",
       "1      0       0.0      0.0          kataisa   \n",
       "2      0       0.0   5423.0       Josh_Ward_   \n",
       "3      0       0.0      0.0       networkMCI   \n",
       "4      0       0.0      0.0         nbharper   \n",
       "\n",
       "                                                Text             TweetID  \\\n",
       "0  RT @HouseOfTraitors: FARAGE  12  -  0 Mandelsc...  732588910078001152   \n",
       "1  @TheBriefing2016 @HillaryClinton Can Hillary s...  732588910073778176   \n",
       "2  RT @HQUESTED: Harvey price just said cunt on n...  732588910061232128   \n",
       "3  @xonighttimexo I will put them in a Safety dep...  732588910056902656   \n",
       "4  you should listen, but you probably won't bc y...  732588910069620736   \n",
       "\n",
       "   Verified  \n",
       "0       1.0  \n",
       "1       1.0  \n",
       "2       1.0  \n",
       "3       1.0  \n",
       "4       1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([data1, data2, megaSpam, megaNonSpam])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FavCount</th>\n",
       "      <th>RtCount</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Text</th>\n",
       "      <th>TweetID</th>\n",
       "      <th>Verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3246372</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>meet me on ELIMINATE pro!!</td>\n",
       "      <td>6168916131</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246373</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my twitter</td>\n",
       "      <td>6170059145</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246374</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exploring this thing...</td>\n",
       "      <td>6171947104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246375</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>learning the rap ice ice baby LOL, not very gd...</td>\n",
       "      <td>6172856187</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246376</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clipse, B.o.B и J.Cole</td>\n",
       "      <td>6174743151</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Class  FavCount  RtCount ScreenName  \\\n",
       "3246372      0       NaN      NaN        NaN   \n",
       "3246373      0       NaN      NaN        NaN   \n",
       "3246374      0       NaN      NaN        NaN   \n",
       "3246375      0       NaN      NaN        NaN   \n",
       "3246376      0       NaN      NaN        NaN   \n",
       "\n",
       "                                                      Text     TweetID  \\\n",
       "3246372                         meet me on ELIMINATE pro!!  6168916131   \n",
       "3246373                                         my twitter  6170059145   \n",
       "3246374                            exploring this thing...  6171947104   \n",
       "3246375  learning the rap ice ice baby LOL, not very gd...  6172856187   \n",
       "3246376                             Clipse, B.o.B и J.Cole  6174743151   \n",
       "\n",
       "         Verified  \n",
       "3246372       NaN  \n",
       "3246373       NaN  \n",
       "3246374       NaN  \n",
       "3246375       NaN  \n",
       "3246376       NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found error: nan, <class 'float'>\n",
      "Found error: nan, <class 'float'>\n",
      "Found error: nan, <class 'float'>\n",
      "Found error: nan, <class 'float'>\n",
      "Found error: nan, <class 'float'>\n",
      "Found error: nan, <class 'float'>\n",
      "Found error: nan, <class 'float'>\n",
      "Found error: nan, <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "def cleanWord(word):\n",
    "    word = \"\".join([c for c in word.lower() if c in whitelist])\n",
    "    return word\n",
    "\n",
    "def invalidWord(word):\n",
    "    if (len(word) == 0 or word[0] == '@' or word == '-pron-'):\n",
    "        return True\n",
    "    word = cleanWord(word)\n",
    "    return len(word) == 0\n",
    "\n",
    "def cleanText(text):\n",
    "    if not isinstance(text, str):\n",
    "        print('Found error: {}, {}'.format(text, type(text)))\n",
    "        text = str(text)\n",
    "#     output = []\n",
    "#     doc = nlp(text)\n",
    "#     for tok in doc:\n",
    "#         if tok.pos_ in ent_whitelist:\n",
    "#             output.append(tok.lemma_)\n",
    "    words = text.split(' ')\n",
    "    output = [cleanWord(word) for word in words if not invalidWord(word)]\n",
    "    return ' '.join(output)\n",
    "\n",
    "with multiprocessing.Pool(8) as p:\n",
    "#     cleanedData = p.map(cleanText, cleanData, 100)\n",
    "    cleanData = p.map(cleanText, data['Text'], 100)\n",
    "#     for text in data[\"Text\"]:\n",
    "#     #     print(type(text))\n",
    "#         cleanData.append(cleanText(str(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanData = [' '.join([x.lower() for x in y.split(' ') if len(x) > 0 and x[0] != '@']) for y in cleanData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'combo chemothrpy radiation thrpy andor surgery in treating ppl w highrisk kidney tumors httpbitly5rdq4x'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanData[-12312]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer()\n",
    "# for i in range(0, len(cleanData) - 9999, 10000):\n",
    "# #     X = vectorizer.fit_transform(cleanData[i:i+10000])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X.shape\n",
    "# X.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = LabelEncoder()\n",
    "# y = encoder.fit_transform(data[\"Class\"])\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.shape)\n",
    "print(len(cleanData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1409704 1409704\n",
      "4229112 4229112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/citrus2019/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/citrus2019/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clean_train, clean_test, y_train, y_test = train_test_split(cleanData, y, test_size=0.25, random_state=42)\n",
    "print(len(clean_test), len(y_test))\n",
    "print(len(clean_train), len(y_train))\n",
    "vectorizer = CountVectorizer()\n",
    "X_vec = vectorizer.fit_transform(clean_train)\n",
    "\n",
    "# classifier = GradientBoostingClassifier()\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_vec, y_train)\n",
    "\n",
    "y_vec = vectorizer.transform(clean_test)\n",
    "y_hat = classifier.predict(y_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GradientBoostingClassifier()\n",
    "classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(y)\n",
    "# Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8267877511874834"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_hat)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_hat)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PICKLE EVERYTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('thepickle_LR_beta.pkl', 'bw') as f:\n",
    "#     pickle.dump([encoder, vectorizer, classifier], f)\n",
    "    pickle.dump([vectorizer, classifier], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = classifier.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100\n",
    "top_k = np.argpartition(coefs, -k)[-k:]\n",
    "top_k_sorted=top_k[np.argsort(coefs[top_k])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pornoru',\n",
       " 'ipads',\n",
       " 'httpbitlyddypiw',\n",
       " 'httplinkbeecomen25t',\n",
       " 'wwwvaldecyalvesblogspotcom',\n",
       " 'httpbitlyeziread',\n",
       " 'chatroulette',\n",
       " 'httpbitlysr9wm',\n",
       " 'luvmystripes',\n",
       " 'asfc',\n",
       " 'soshified',\n",
       " 'httplovinmysistascom',\n",
       " 'httpwwwyoutubecomwatchv674o8mmurfc',\n",
       " 'httpwwwpulsepowernowcom',\n",
       " 'httpbitlycu9ead',\n",
       " 'httpbitly3tmcrn',\n",
       " 'dateyocom',\n",
       " 'dubli',\n",
       " 'httpappsfacebookcomiplpredict',\n",
       " 'papiroflexia',\n",
       " 'httpisgda3eeu',\n",
       " 'httpwwwplaymobsterworldcomplatformtwittersourceonelinefight',\n",
       " 'freegiladshalit',\n",
       " 'heartfeltquotes',\n",
       " 'cbb7',\n",
       " 'httpbitly4i1wfq',\n",
       " 'jpg',\n",
       " 'httpwwwjinxbeatzcom',\n",
       " 'thatswhatshesaid',\n",
       " 'httpstoresebaycomhistoricdvds',\n",
       " 'efrcm',\n",
       " 'upskirt',\n",
       " 'httpbitlyb5e7kt',\n",
       " 'httpagd7d4b29',\n",
       " 'theillblogcom',\n",
       " 'wwwmodlowarvaicom',\n",
       " 'sbchocolate',\n",
       " 'algarve',\n",
       " 'cuteasxkiki',\n",
       " 'nexus',\n",
       " 'httpdrfuzzcom',\n",
       " 'httpwwwelegantvisionofbeautycom',\n",
       " 'httpwwwtinychatcomtonydofat',\n",
       " 'httpbitly8yjfas',\n",
       " 'ihatequotes',\n",
       " 'iconfess',\n",
       " 'stonerwhen',\n",
       " 'wwwchchjobsconz',\n",
       " 'httpbitlyard1gu',\n",
       " 'untranslatable',\n",
       " 'httpwwwnwayorg',\n",
       " 'dreidel',\n",
       " 'httpbitly1greda',\n",
       " 'lambokmcrmy',\n",
       " 'httpbitlyazgmqt',\n",
       " 'hafshop',\n",
       " 'httpcligs50bwn',\n",
       " 'theweatherchannel',\n",
       " 'httpblognwayorg',\n",
       " 'worldcup',\n",
       " 'wwwtwitreplynetx1443',\n",
       " 'groraum',\n",
       " 'yuwie',\n",
       " 'twuizzer',\n",
       " 'httpfollowersr6',\n",
       " 'httphotshorturlcomabx13',\n",
       " 'moneytip',\n",
       " 'mesothelioma',\n",
       " 'httpbitly9nyw87',\n",
       " 'blackmamaquotes',\n",
       " 'httpbitly54u1hm',\n",
       " 'httpbitlydel8gm',\n",
       " 'ichatby',\n",
       " 'httpbitly6ns0sc',\n",
       " 'httpbitly3rxfxr',\n",
       " 'httpradiodiscocom',\n",
       " 'randomspotlight',\n",
       " 'twinomi',\n",
       " 'httpbitlyexpatdating',\n",
       " 'followbackgroup',\n",
       " 'httpbitly9c29sf',\n",
       " 'readcast',\n",
       " 'httpbitlycyztwb',\n",
       " 'ravelrock',\n",
       " 'httpwwwtherageradiocom',\n",
       " 'opensky',\n",
       " 'haiti',\n",
       " 'wwwsoccerpooltjenl',\n",
       " 'wwwatatro',\n",
       " 'httpfaxocomt',\n",
       " 'nouaint',\n",
       " 'frestival',\n",
       " 'httpbitly6bilk3',\n",
       " 'teamfollowback',\n",
       " 'feminazi',\n",
       " 'ipad',\n",
       " 'margemsul',\n",
       " 'fretado',\n",
       " 'habbort',\n",
       " 'geleira']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = vectorizer.get_feature_names()\n",
    "[feats[x] for x in top_k_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
